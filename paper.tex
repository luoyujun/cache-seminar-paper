% Preamble {{{1
\documentclass[a4paper]{scrartcl}

\usepackage[utf8]{inputenc} % Assume this file is encoded in UTF-8.
\usepackage[T1]{fontenc}    % Don't fake umlauts etc.
\usepackage{lmodern}        % Use the lmodern font (http://tex.stackexchange.com/a/65103).
\usepackage{microtype}      % Better microtypography (http://www.ctan.org/pkg/microtype)
\usepackage{hyperref}       % Clickable hyperlinks, load before `glossaries`
\usepackage{cleveref}       % Use `\cref{fig:foo}` instead of `figure~\ref{fig:foo}`.
                            % Load after `hyperref`.  See
                            % <https://tex.stackexchange.com/q/36295>
\usepackage{comment}        % Comment out sections of text.
\usepackage{mathtools}      % Improved facilities for typesetting mathematical formulae
\usepackage{dirtytalk}      % ...

% Use ISO 8601, like a reasonable person.  See <https://tex.stackexchange.com/a/152394>.
\usepackage[style=iso]{datetime2}

% Source code listings with improved syntax highlighting
\usepackage{minted}
\usemintedstyle{pastie}

\usepackage{color}
\definecolor{bg}{rgb}{0.95,0.95,0.95}
\setminted{bgcolor=bg}

% Keep using ISO 8601 consistently, like an even more reasonable person.  See
% <https://tex.stackexchange.com/q/231208>.
\usepackage[date=edtf, urldate=edtf]{biblatex}
\addbibresource{paper.bib}

\usepackage[xindy, toc, acronym, nomain]{glossaries} % Load after `hyperref`.

\makeglossaries

\usepackage{tikz}
\usetikzlibrary{datavisualization}
% \usetikzlibrary{datavisualization.formats.functions}

% See <https://tex.stackexchange.com/a/155317>, <https://tex.stackexchange.com/a/320521>
% and <https://tex.stackexchange.com/a/75507>.
% \usepackage{tikzscale}

\newacronym{emm}{EMM}{external memory model}
\newacronym{hdd}{HDD}{hard disk drive}
\newacronym{ram}{RAM}{random access machine}
\newacronym{smt}{SMT}{simultaneous multithreading}
\newacronym{tlb}{TLB}{translation lookaside buffer}
\newacronym{ssd}{SSD}{solid-state drive}

\newcommand{\article}{article} % report, paper?

% Top matter {{{1
\title{Algorithms for Hardware Caches}
\author{Lukas Waymann}

% Body {{{1
\begin{document}
\maketitle
\newpage

\begin{abstract}
   % What?
   Typical present-day CPUs have two or more levels of caches.  This \article{} presents
   the basic techniques used to optimize program performance based on knowledge about how
   these hardware caches function.

   The abstract \gls{emm} for memory hierarchies is explained and a small selection of
   algorithms developed for it
   % analyzed under it
   are explored mathematically and empirically.
\end{abstract}
\newpage

\tableofcontents
\newpage

\glsresetall % Reset the use status of all acronyms.

\section{Introduction}
% What is this paper about?  Why learn about them?  How much performance is at stake?

% What are hardware caches?
A hardware cache is a comparatively
% relatively
fast and small physical memory.  It stores a subset of the data present in slower, larger
memory that is expected to be used again soon.  The purpose of this additional memory is
to reduce the number of accesses to the underlying slower storage.

% Why caches?
There are fundamental reasons that having one single, uniform
% homogeneous
type of memory is not viable.  No signal can propagate faster than the speed of light.
Thus, every storage technology can only reach a finite amount of data within a desired
access latency \cite[p.~2]{afmh}.

The most ubiquitous example for hardware caches is the hierarchy of
% are the various levels (most commonly 2 or 3) of
CPU caches that are found on almost all present-day CPUs.  They are designated L1 cache,
L2 cache, and so on, with L1 being the fastest and smallest level.  The underlying storage
for CPU caches is the main memory.

There are more storage levels that comprise
% constitute
the \emph{memory hierarchy} of a computer along with CPU caches and main memory.  For
example \glspl{hdd} and \glspl{ssd}. % Also: registers, internal buffers of HDDs and SSDs,
                                     % (tapes?), ...
% Focus on CPU caches.  Why?
However, swapping to \glspl{hdd} and \glspl{ssd} continues to become somewhat less common
as main memory sizes increase.  Even non-server systems can currently support 64 GiB of
main memory, eliminating the need for swapping to disk under many workloads.

I will focus on how to use CPU caches effectively and the resulting
% enabled
performance gains in this \article{}.
% TODO: what about TLB?

\section{Motivation} % So what?
%    Three things Really Matter for performance.  The first one is Algorithm, the second
%    one is your code being Non-Blocking, and the third one is Data Locality."
%       -- http://ithare.com/c-performance-common-wisdoms-and-common-wisdoms/

% TODO: move this paragraph?
Hardware caches are managed by hardware directly.  They are generally opaque to the
operating system and other programs.  That is, software has no direct control over the
contents of a hardware cache.

% So what?  Why learn about hardware caches?  How much performance do I gain/lose
% depending on how *cache-friendly* my algorithm/code is?

% We will see that
Despite this, two algorithms solving the same problem with the same asymptotic complexity
(in the same \(\Theta(g(n))\)) may differ in performance by two orders of magnitude
because of different \emph{memory access patterns}~\cite{bigos}.  We will see an example
of this in section TODO.

In a nutshell, hardware caches are ubiquitous but the performance improvements they
provide are conditional.
\begin{comment}
   To use them effectively,
   % To obtain optimal performance,
   algorithms must be designed and implemented with the architecture
   % design, structure, manner of functioning, inner workings, properties
   of hardware caches in mind.
\end{comment}
Effective use of hardware caches requires knowledge about how they work.
% their architecture.
Algorithms must be designed and implemented observing this knowledge.
% their interactions with hardware caches.

% TODO: and *how* do I make effective use of hardware caches?

% \section{Basic Principles}
\section{Basic Concepts}
% \section{Key Terms}
% That sounds boring.

\subsection{Spatial Locality}
Data is loaded from bigger, slower memory into smaller, faster memory (e.g. from main
memory into the CPU cache) in \emph{blocks}.

Moving down the memory hierarchy, access latencies increase faster than the
\emph{obtainable} bandwidth: \say{[w]e can still achieve large bandwidths by accessing
many close-by bits together [...].  Access to large \emph{blocks} [emphasis added] of
memory is almost as fast as access to a single bit},~\cite[p.~2]{afmh}.

% TODO: move this.
% Consider the program shown in \cref{lst:array-sum}.  It repeatedly loops over an array
% to compute the sum of its elements.  Before exiting, it prints the CPU time spend
% summing the array.

\begin{listing}
   \inputminted[firstline=3]{c}{array-sum/array-sum.c}
   \caption{This is C code}
   \label{lst:array-sum}
\end{listing}

% This program is likely to have excellent spatial locality: the array...

% \begin{figure}[htb]
\begin{figure}
   \centering
   \begin{tikzpicture}
      \datavisualization
      [scientific axes=clean,
       x axis={label={Array size (KiB)}, length=0.8\textwidth},
       y axis={label={Processor time (ms)}, length=6cm},
       visualize as scatter,
       scatter={style={mark=*, mark options={scale=.65}}}]
         % See <https://tex.stackexchange.com/q/198323>.
         data [read from file=array-sum/size-time.csv, separator=\space];
   \end{tikzpicture}
   \caption{This figure took way too long to create}
   \label{fig:array-sum}
\end{figure}

% See \cref{fig:array-sum}.  What's going on here?

\subsection{Temporal Locality}

\subsection{Cache Hit}

\subsection{Cache Miss}
% TODO: what happens when we miss?  How bad is it?  What about \gls{smt}?

\subsection{Cache Line} % or Cache Block
% On x86/x64, cache line is 64 bytes for many years now.
%    -- http://ithare.com/c-for-games-performance-allocations-and-data-locality/

\subsection{External Memory Model}
The \gls{emm} is a widely used
% TODO: is it?)
extension of the \gls{ram} model.

\clearpage

\printglossary[type=\acronymtype] % Print the list of acronyms.

\printbibliography[heading=bibintoc]

\end{document}

% vim: tw=90 sts=-1 sw=3 et fdm=marker
