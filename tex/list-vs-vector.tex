\section{Example: \texttt{std::vector} vs. \texttt{std::list}}

\alts{%
   The C++ program shown in \cref{lst:ithare},
   The following C++ program,
}%
, adapted from \textcite{bigos}, initializes a number of \acrshort{stl} containers
with random numbers and measures the processor time needed to \alts{sum all of them,
compute the sum}.
%
I first ran it with \mintinline{cpp}{Container} being a type alias for
\mintinline{cpp}{std::list}, then for \mintinline{cpp}{std::vector}.%
\footnote{%
   Each compiled with \x{the \gls{gcc}} and \mintinline{text}{-O3} and
   \mintinline{text}{-march=native}
}
Either way, the asymptotic complexity is \(\Theta(N)\).

\begin{center}
   \inputminted[firstline=29]{cpp}{ithare/list-vs-vector.cpp}
   \captionof{listing}{Compute the Sum of a Container, adapted from \textcite{bigos}}
   \label{lst:ithare}
\end{center}

\newread\file
\openin\file=ithare/speedup.txt
\read\file to \speedup
\closein\file

% This doesn't work: `\num{\input{ithare/speedup.txt}}`.

% > In trying to explain this difference, we'll need to get into educated-guesswork area.
% > For MSVC and gcc, the performance difference between vector<> and list<> is pretty
% > much in line with the difference between typical cached access times (single-digit
% > clocks) and typical uncached access times (100-150 clocks).  As access patterns for
% > vector<> are expected to use CPU prefetch fully and list<> under the patterns in
% > Listing 1 is pretty much about random access to memory, which cannot be cached due to
% > the size, this 100-150× difference in access times can be expected to translate into
% > 100-150× difference in performance.
%      -- https://accu.org/index.php/journals/2268

% > [T]he performance difference between vector<> and list<> is pretty
% > much in line with the difference between typical cached [...] and typical uncached
% > access times.
%      -- https://accu.org/index.php/journals/2268

% \noindent
% \alts{{The result is that, when}, When}  computing the
% sum \alts{runs, is} \num[round-mode=places, round-precision=0]{\speedup} times faster.
\alts{My, The} result is that computing the sum \alts{runs, is} \num[round-mode=places,
round-precision=0]{\speedup} times faster when using \mintinline{cpp}{std::vector}.  Some
of this difference can certainly be attributed to space overhead of the linked list and
the added indirection, but the more \emph{cache-friendly} memory access pattern of
\mintinline{cpp}{std::vector} is \alts{decisive, key, crucial, vital}~\cite[5\psq]{bigos}.
Using \mintinline{cpp}{std::list} incurs \say{random access to memory} in this
example~\cite[6]{bigos}.

% vim: tw=90 sts=-1 sw=3 et fdm=marker
