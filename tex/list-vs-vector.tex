\section{Example: \texttt{std::vector} vs. \texttt{std::list}}
\label{sec:lvv}

\alts{%
   The C++ program shown in \cref{lst:ithare},
   The following C++ program,
}%
, adapted from \textcite{bigos}, initializes a number of \acrshort{stl} containers
with random numbers and measures the processor time needed to \alts{sum all of them,
compute the sum}.
%
I first ran it with \mintinline{cpp}{Container} being a type alias for
\mintinline{cpp}{std::list}, then for \mintinline{cpp}{std::vector}.%
\footnote{%
   Each compiled with \x{the \gls{gcc}} and \mintinline{text}{-O3} and
   \mintinline{text}{-march=native}
}
Either way, the asymptotic complexity is \(\Theta(N)\).

\begin{center}
   \inputminted[firstline=29]{cpp}{ithare/list-vs-vector.cpp}
   \captionof{listing}{Compute the Sum of a Container, adapted from \textcite{bigos}}
   \label{lst:ithare}
\end{center}

\newread\file
\openin\file=ithare/speedup.txt
\read\file to \speedup
\closein\file

% This doesn't work: `\num{\input{ithare/speedup.txt}}`.

% > In trying to explain this difference, we'll need to get into educated-guesswork area.
% > For MSVC and gcc, the performance difference between vector<> and list<> is pretty
% > much in line with the difference between typical cached access times (single-digit
% > clocks) and typical uncached access times (100-150 clocks).  As access patterns for
% > vector<> are expected to use CPU prefetch fully and list<> under the patterns in
% > Listing 1 is pretty much about random access to memory, which cannot be cached due to
% > the size, this 100-150× difference in access times can be expected to translate into
% > 100-150× difference in performance.
%      -- https://accu.org/index.php/journals/2268

% > [T]he performance difference between vector<> and list<> is pretty
% > much in line with the difference between typical cached [...] and typical uncached
% > access times.
%      -- https://accu.org/index.php/journals/2268

% \noindent
% \alts{{The result is that, when}, When}  computing the
% sum \alts{runs, is} \num[round-mode=places, round-precision=0]{\speedup} times faster.
\alts{My, The} result is that computing the sum \alts{runs, is} \num[round-mode=places,
round-precision=0]{\speedup} times faster when using \mintinline{cpp}{std::vector}.  Some
of this difference can \x{certainly} be attributed to space overhead of the linked list
and the added indirection, but the more cache-friendly memory access pattern of
\mintinline{cpp}{std::vector} is \alts{decisive, key, crucial, vital}~\cite[5\psq]{bigos}.
Using \mintinline{cpp}{std::list} incurs \say{random access to memory} in this
example~\cite[6]{bigos}.

\subsection{``True'' OO Style}

% TODO.  Having a vector of pointers to dynamically allocated object derived from some
% base class in true OO style (tm) probably isn't going to make the cache happy.  Bjarne
% Stroustrup talked about this [1].  Strongly related: data-oriented design [3].
%
% [1]: https://youtu.be/0iWb_qi2-uI?t=51m22s
%      "GoingNative 2012: Day 1 Keynote - Bjarne Stroustrup: C++11 Style"
% [2]: https://channel9.msdn.com/Events/GoingNative/GoingNative-2012/Keynote-Bjarne-Stroustrup-Cpp11-Style
%      "GoingNative 2012: Day 1 Keynote - Bjarne Stroustrup: C++11 Style"
% [3]: https://youtu.be/rX0ItVEVjHc
%      "CppCon 2014: Mike Acton 'Data-Oriented Design and C++'"

% A nice compact, flat container isn't going to cut it if it contains pointers.

In object-oriented systems, objects are typically referred to by pointers to a common base
class.  A polymorphic container of such pointers allows for dynamic dispatch of virtual
functions.  However, this carries the risk of degrading the \x{superior} performance of a
sequential data structure to that of a list%
% ~\cite[\href{https://youtu.be/0iWb_qi2-uI?t=51m22s}{51:22}]{stroustrup-talk}.
~\cite[51:22]{stroustrup-talk}.
See \cref{fig:true-oo}.

\begin{figure}
   \centering
   \input{tex/oo-picture}
   \captionsetup{width=.9\linewidth} % FIXME: hacks!
   \caption[Array of Pointers]{Array of Pointers; while the array is compact, the actual
   objects may not be laid out sequentially in memory.}
   \label{fig:true-oo}
\end{figure}

\subsection{Unrolled List}

% TODO.  Talk about unrolled lists and software prefetching.

% vim: tw=90 sts=-1 sw=3 et fdm=marker
