\subsection{Cache Line} % or Cache Block
% https://en.wikipedia.org/wiki/CPU_cache#Cache_entries
%
% > On x86/x64, cache line is 64 bytes for many years now.
%      -- http://ithare.com/c-for-games-performance-allocations-and-data-locality/
% > In early caches these lines were 32 bytes long; nowadays the norm is 64 bytes.
%      -- Drepper, p. 15
% > It is not possible for a cache to hold partial cache lines.
%      -- Drepper, p. 16
% > A cache line is the "unit" of data you transfer to a cache.
%      -- http://www.cs.umd.edu/class/sum2003/cmsc311/Notes/Memory/introCache.html
\emph{Cache lines} or \emph{cache blocks} are the unit of data transfer between main
memory and cache.  They have a fixed size, which has been \say{64 bytes for many years} on
x86/x64 CPUs~\cites{ithare-paadl}[\href{https://youtu.be/WDIkqP4JbkE?t=21m41s}{21:41}]
{scott-meyers-talk}.%
\footnote{%
% > The original Pentium 4 processor also had an eight-way set associative L2 integrated
% > cache 256 KB in size, with 128-byte cache blocks.
%      -- https://en.wikipedia.org/wiki/CPU_cache#Example
% TODO: what about the block size of main memory?  Should it be the same?
Line sizes aren't \emph{necessarily} \alts{identical, homogenous} among a CPU's caches.
The Intel Pentium 4 processor had an \texttt{L1d} cache with \say{64 bytes per cache
line}~\cite[p.~9]{pentium4} but an \texttt{L2} cache with \say{128 bytes per cache
line}~\cite[p.~11]{pentium4}.}
\begin{comment}
   \multiplefootnoteseparator%
   % See <https://tex.stackexchange.com/a/71015>.
   \footnote{This can also be checked on the command line:
   \mintinline{bash}{cat /proc/cpuinfo | grep cache_alignment}}
\end{comment}
% > It means that as soon as you've accessed any single byte in a cache line, all the
% > other 63 bytes are already in L1 cache
%      -- http://ithare.com/c-for-games-performance-allocations-and-data-locality/
\alts{%
   This means accessing a single uncached 32-bit integer entails loading another 60
   adjacent bytes.,
   {This means when a single byte has to be loaded, another 63 adjacent bytes will be as
   well.},
   {When, for example, accessing a single byte that isn't already cached, another 63
   adjacent bytes will be loaded.}
}
% Even when compiling C++ for 64-bit systems, `int` is typically 32-bit.

My E-450 CPU is no exception and both of its data caches have 64-byte cache lines.%
\footnote{See \cref{app:cpuinfo}.}
% \begin{minted}[gobble=3]{bash}
%    $ getconf LEVEL1_DCACHE_LINESIZE; getconf LEVEL2_CACHE_LINESIZE
%    64
%    64
% \end{minted}
%stopzone
% \footnote{%
%    \mintinline{bash}!$ getconf LEVEL1_DCACHE_LINESIZE; getconf LEVEL2_CACHE_LINESIZE!\\
%    %stopzone
%    \noindent\mintinline{bash}!64!\\
%    \noindent\mintinline{bash}!64!
% }
We can verify this quite easily.  Consider \cref{lst:line-size}.  It loops over an array
with an increment given at compile time as \texttt{STEP} and measures the processor time.
\begin{center}
   \inputminted[firstline=27]{c}{line-size/line-size.c}
   \captionof{listing}{%
      Loop over \mintinline{text}{array} with increment \mintinline{text}{STEP}}
   \label{lst:line-size}
\end{center}
The results for different values of \texttt{STEP} are plotted in \cref{fig:line-size}.
% Starting from a step size of 16, the time roughly halves every time the step size is
% doubled.  For the first 4 step sizes however, it is almost constant.
As expected, the time roughly halves whenever the step size is doubled --- but only from a
step size of 16.  For the first 4 step sizes, it is almost constant.

% The reason why the loops take the same amount of time has to do with memory.  The
% running time of these loops is dominated by the memory accesses to the array, not by the
% integer multiplications.
%    -- https://igoro.com/archive/gallery-of-processor-cache-effects/
This is because the run times are \alts{primarily due to, dominated by} memory accesses.
Up to a step size of 8, every 64-byte line has to be loaded.  At 16, the values we modify
are 128 bytes apart,%
\footnote{16 \texttt{int64\_t} values of 8 bytes each}
so every other cache line is skipped.  At 32, three out of four cache lines are skipped,
and so on~\cite[cf.][example 2]{gallery}.

\begin{comment}
   \begin{listing}
      \inputminted[firstline=27]{c}{line-size/line-size.c}
      \caption{Loop over \mintinline{text}{array} with increment \mintinline{text}{STEP}}
      \label{lst:line-size}
   \end{listing}
\end{comment}

\begin{figure}
   \centering
   \begin{tikzpicture}
      \datavisualization
      [scientific axes=clean,
       x axis={logarithmic,
               ticks={major={at={1 as \textbf{1}, 2 as \textbf{2}, 4 as \textbf{4},
                                 8 as \textbf{8}, 16, 64, 256, 1024}},
                      minor={at={32, 128, 512}}},
               label={Step size}, length=0.8\textwidth},
       y axis={logarithmic,
               % ticks={major={at={4, 16, 64, 256}}, minor={at={8, 32, 128}}},
               % ticks={major={at={6, 12, 24, 48, 92, 184}}},
               ticks={major={at={5, 10, 20, 40, 80, 160, 320}}},
               label={Processor time (ms)}, length=6cm},
       visualize as scatter,
       scatter={style={mark=*, mark options={scale=.65}}}]
         % See <https://tex.stackexchange.com/q/198323>.
         data [read from file=line-size/line-size.csv, separator=\space];
   \end{tikzpicture}
   \caption{Processor times for running \cref{lst:line-size}}
   \label{fig:line-size}
\end{figure}

% Talk about how the term cache line is commonly conflated to mean an appropriately sized
% and *aligned* block of main memory that can be loaded into a cache line.  This is how it
% works, right?  Or can we load blocks starting at arbitrary addresses into a cache line?
% One could even imagine loading memory that isn't even contiguous.  Most sources don't
% seem to clear any of this up.  See <https://stackoverflow.com/q/3928995> ("How do cache
% lines work?")
\begin{comment}
   The term cache line is also used to refer to \alts{identically, appropriately} sized
   blocks in main memory.
   % that may be loaded into cache.
   These blocks are fixed:
   % I.e., each byte in main memory falls exactly into one cache line.
   % The boundaries

   Cache lines in main memory are fixed.
   % Data is not loaded starting from arbitrary addresses, but only from addresses that
   % are multiples of the cache line size.
   Data blocks that are loaded don't start at arbitrary addresses, but at multiples of the
   cache line size.
\end{comment}
% See <https://en.wikipedia.org/wiki/Partition_of_a_set>.  XXX: I feel like there's some
% kind of conflation of ideas going on here.
Both cache and main memory can be thought of as being partitioned%
% \footnote{%
%    In the set-theoretic sense
% }
\ (in the set-theoretic\x{al}\ sense) % https://en.wiktionary.org/wiki/set-theoretic
into \alts[3]{cache line-sized blocks, blocks of that size, cache lines}.  \alts[2]{{That
is, d}, D}ata is \alts{not, neither} \alts{read or written, loaded} starting from
arbitrary main memory addresses,
% ...nor is it loaded into arbitrarily aligned blocks in cache.
but only from addresses that are multiples of the cache line size.
% The starting address will by a multiple of the cache line size.

% TODO: this probably has some implications about aligning data.

% TODO: maybe talk about the 64-bit bus width and burst mode as well.  And maybe about how
% a write requires a read if we only write part of a cache line and the optimization of
% adding dummy writes (I think Andrei talked about this).
%
% [1]: https://stackoverflow.com/q/39182060 "Why isn't there a data bus which is as wide
%      as the cache line size?"

% vim: tw=90 sts=-1 sw=3 et fdm=marker
