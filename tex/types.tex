\section{Types of CPU Caches}
% > Most modern desktop and server CPUs have at least three independent caches: an
% > instruction cache to speed up executable instruction fetch, a data cache to speed up
% > data fetch and store, and a translation lookaside buffer (TLB) used to speed up
% > virtual-to-physical address translation for both executable instructions and data.
%      -- https://en.wikipedia.org/wiki/CPU_cache#Overview
% > There are three common types of CPU caches: ...
%      -- Scott Meyers (talk at code::dive)
Current x86 CPUs \alts{generally, typically, commonly} have three main types of caches:
data caches, instruction caches, and \glspl{tlb}%
~\cite[\href{https://youtu.be/WDIkqP4JbkE?t=11m07s}{11:07}]{scott-meyers-talk}.
Some caches are used for data as well as instructions and are called \emph{unified}.%
~\cite[20]{drepper2007}.
\alts{{A processor may have multiple caches of each type, which}, {Multiple caches of each
type may be present, and}} are organised into numerical \emph{levels}
\alts{{starting at 1, the smallest and fastest level,},}
based on their size and speed.
% Each added level is bigger and slower than its predecessor.
% The smallest and fastest is level 1.

% TODO?  The reason to have multiple levels...

% > Often there are separate L1 caches for instructions and data
%      -- Algorithms for Memory Hierarchies, page 3
% > Systems nowaeays have at-least two levels of cache
%      -- Algorithms for Memory Hierarchies, page 172
% > [T]he caches from L2 on are unified caches which contain both code and data
%      -- Drepper, p. 31
% > Later Intel models have shared L2 caches for dual-core processors.  For quad-core
% > processors we have to deal with separate L2 caches for each pair of two cores.
%      -- Drepper, p. 35

% Terminology / Nomenclature.
In practice, a \alts{currently, presently} representative%
\footnote{%
   % https://en.wikipedia.org/wiki/Bobcat_(microarchitecture)
   E.g. for AMD Family 14h processors~\cite[30--32]{14h},
   % https://en.wikipedia.org/wiki/List_of_AMD_CPU_microarchitectures
   % https://en.wikipedia.org/wiki/Zen_(microarchitecture)
   % 32 KiB L1d, 64 KiB L1i, 512 KiB L2, 8 to 16 MiB L3
   AMD Zen (17h)~\cite{zen}, and
   % https://en.wikipedia.org/wiki/Kaby_Lake
   % https://en.wikipedia.org/wiki/Skylake_(microarchitecture)
   % 32 KiB L1d, 32 KiB L1i, 256 KiB L2, 2 to 8 MiB L3
   Intel Skylake desktop processors%
   ~\cite[figure 2-1, table 2-4]{skylake}
   % ~\cite[figure 2-1, \pno~2-2, table 2-4, \pno~2-6]{skylake}.
   % ~\cite[{2-2}, {2-6}]{skylake}.
   % <https://en.wikipedia.org/wiki/Bulldozer_(microarchitecture)> is too weird.
}
x86 cache hierarchy consists of:
\begin{itemize}
   % https://en.wikipedia.org/wiki/Cache_hierarchy#Shared_versus_private
   \item Separate level 1 data and instruction caches of 32 to 64 KiB for each core
      (denoted \gls{l1d} and \gls{l1i} by  \textcite[14--15]{drepper2007}).
      % TODO?  Why have a separate instruction cache?
      Machine instructions in \gls{l1i} are already decoded%
      ~\cite[31, 56]{drepper2007}.
      % ~\cite[14, 31, 56]{drepper2007}.
   % \item A level 2 cache for \say{both code and data}~\cite[31]{drepper2007}.
   \item A unified \gls{l2} cache of 256 to 512 KiB for each core.
   \item Often a unified \gls{l3} cache of 2 to 16 MiB shared between all cores.
   \item TODO: Some \glspl{tlb} I guess.
\end{itemize}

% \subsection{Access Times}
% http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/
% http://www.getitwriteonline.com/archive/040201hyphadj.htm
\alts{Estimates, Order-of-magnitude estimates} of typical access latencies \alts[2]{are as
follows, are given by \textcite{ithare-cycles}.}%
\footnote{%
   Intel~\cite[table 2-4]{skylake},
   \textcites
   % {ithare-paadl}{ithare-wisdoms}
   [\href{https://youtu.be/WDIkqP4JbkE?t=17m52s}{17:52}, slide 18]{scott-meyers-talk}
   [2--3, 171]{afmh}[16, 20--21]{drepper2007} all give comparable numbers for various
   architectures.
   % [\ppno~16, 20--21, fig. 3.10]{drepper2007}
}

\begin{center}
   \begin{tabular}{ r | c c c c }
             & \gls{l1d} & \gls{l2} & \gls{l3} & Main Memory \\ \hline
      Cycles & 3--4      & 10--12   & 30--70   & 100--150
   \end{tabular}
\end{center}
%
% These are taken from~\textcite{ithare-cycles} but comparable numbers are given by

% > [Instruction] cache is much less problematic than the data cache.
%      -- Drepper, p. 31
The biggest target for optimizations is the data cache.  \say{[Instruction] cache is much
less problematic}~\cite[31]{drepper2007} and optimizations for data and instruction cache
tend to improve \gls{tlb} usage as well%
~\cite[\href{https://youtu.be/WDIkqP4JbkE?t=11m53s}{11:53}]{scott-meyers-talk}.

My laptop's AMD E-450 CPU has cores with \alts{an \gls{l1d} cache of 32 KiB, 32 KiB of
\gls{l1d} cache} and a unified \gls{l2} cache of 512 KiB each.%
\footnote{\Cref{app:cpuinfo} explains how to obtain this information.}
We can both verify these sizes and get \alts{a reasonably good measure, a rough measure,
an approximation} of the access times by profiling
\cref{lst:access-times}
% the \alts{program, listing} below
for different values of \mintinline{text}{SIZE}.%
% FIXME: the label is wrong: should be "Appendix" but is "Section".
\footnote{\Cref{app:cycles} details how.}
% It reads random memory addresses
% The program randomly reads
% locations
% The program repeatedly \alts{reads, accesses} random elements
This program repeatedly \alts{reads, accesses} elements
from \alts[2]{an array of the configured size, a thusly sized array}
in random \alts{order, sequence, succession}.
To do this
\alts{with minimal overhead, efficiently}, the array \alts{is first set up, acts} as a
circular, singly linked list where every element except the last \alts{points to a, has a}
random successor.  When compiled with \mintinline{text}{-DBASELINE}, only this
initialization is done.

% XXX: hacks!  Use the figure environment so that LaTeX won't display this listing after
% the plot showing the results of profiling it.  "LaTeX [only] keeps all floats of the
% same *type* in order" [1].  Use `\captionof` to label the listing correctly as a
% listing.
%
% [1]: https://tex.stackexchange.com/q/127742/#comment290982_127744
\begin{comment}
   \begin{figure}
      \inputminted[firstline=9]{c}{access-times/access-times.c}
      \captionof{listing}{TODO}
      \label{lst:access-times}
   \end{figure}
\end{comment}

% \newenvironment{code}{\captionsetup{type=listing}}{}
% \begin{code}
%    \inputminted[firstline=9]{c}{access-times/access-times.c}
%    \caption{TODO}
%    \label{lst:access-times}
% \end{code}

% XXX: hacks!  FIXME: I want to have the same amount of space after adding a caption with
% \captionof to a minted listing as there would be after a normal floating minted listing.
% See <https://tex.stackexchange.com/a/162074>.
% \captionsetup[listing]{aboveskip=5pt, belowskip=\baselineskip}

% Actually, don't use a float.  The listing should be allowed to span multiple pages which
% floats aren't.
%
% [1]: https://tex.stackexchange.com/q/14522/#comment484569_75880
% [2]: https://tex.stackexchange.com/q/175650
%      "How to allow page break inside a float environment?"
% [3]: https://tex.stackexchange.com/q/12428
\begin{center} % XXX: hack to get normal spacing after the caption and before the listing.
   \inputminted[firstline=12]{c}{access-times/access-times.c}
   % \captionof{listing}{}
   % \captionof{listing}{Randomly Access Elements of \mintinline{text}{array}}
   \captionof{listing}{Randomly Read Array Elements}
   % \captionof{listing}{Random Reads\label{lst:access-times}}
   \label{lst:access-times}
\end{center}

% https://tex.stackexchange.com/a/82473
% \global\csname @topnum\endcsname 0

% \Cref{fig:access-times} shows the \alts{difference, deltas} of CPU cycles used when and
% when not having defined \mintinline{text}{BASELINE}.
\Cref{fig:access-times} shows the extra CPU cycles used by \cref{lst:access-times}
\alts[2]{above, in addition to, compared to} the \mintinline{text}{BASELINE} version for
different array sizes.
That is, only the cycles used by the main loop are \alts{given, counted}, not those for
initialization.  I divided by \mintinline{text}{N} to get the cycles spent \alts{per, on
each} loop iteration.

Up to 32 KiB, each access takes almost exactly 3 cycles.%
\footnote{The numerical results are shown in \vref{tab:access-times}.}
This is the \gls{l1d} access \alts{time, latency}.  At 32 KiB (the size of the \gls{l1d})
the time increases to about 3.4 cycles.  This is not surprising since the cache is shared
with other processes and the operating system, so some of our data gets evicted.  The
first dramatic increase happens at 64 KiB followed by smaller increases at 128 and 256
KiB.  I suspect we are seeing a mixture of \gls{l2} and \gls{l1d} accesses, with less and
less \gls{l1d} hits and an \gls{l2} access time of around 25 cycles.

The values from 512 KiB to 128 MiB \alts{exhibit, follow} a similar pattern.  The relative
increase when the array size matches that of the \gls{l2}, 512 KiB, is \alts{greater, more
striking} than for the \gls{l1d} before; possibly because \gls{l2} is a unified cache that
also holds instructions.  Eventually, more and more accesses go to main memory,
\alts{causing, incurring} delays of up to 200 cycles~\cite[cf.][17]{drepper2007}.

\Cref{sec:prefetch} will explain the reason for going through the trouble of conducting
random accesses instead of just reading the array sequentially for this measurement.
% We will see why this measurement was conducted with random instead of sequential
% accesses in \cref{sec:prefetch}.

% XXX: hacks!  Explicit placement specifier without `t` (top) to prevent the figure from
% interrupting the source code listing.
\begin{figure}[hbp]
   \centering
   \begin{tikzpicture}
      \datavisualization[%
         scientific axes=clean,
         x axis={%
            logarithmic,
            ticks={major={
               /pgf/number format/int detect,
               at={
                  2048 as 2, 8192 as 8, 32768 as \textbf{32}, 131072 as 128,
                  524288 as \textbf{512}, 2097152 as \pgfmathprintnumber{2048},
                  8388608 as \pgfmathprintnumber{8192},
                  33554432 as \pgfmathprintnumber{32768},
                  134217728 as \pgfmathprintnumber{131072},
                  % $128\cdot 2^{10}$}}},
                  % $2^{17}$}}},
            }}},
            grid={at={32768, 524288}},
            label={Array Size (KiB)},
            length=0.8\textwidth},
         y axis={include value=0, label={Cycles / Iteration}, length=6cm, grid=at ticks},
         visualize as scatter,
         scatter={style={mark=*, mark options={scale=.65}}}]
         data [read from file=access-times/access-times.csv, separator=\space];
   \end{tikzpicture}
   % \caption{Access Times for Random Reads (\Cref{lst:access-times})}
   \caption{Access Times for Random Reads}
   \label{fig:access-times}
\end{figure}

% vim: tw=90 sts=-1 sw=3 et fdm=marker
